Latent Factor Mixed Models (LFMMs)
========================================================
author: Olivier Francois
date: SSMPG17, September 10, 2017
autosize: true

Outline
========================================================


- Very short introduction to LFMMs


- R packages **lfmm** and **LEA**


- Examples with the dahu SSMPG17 data set


Basic principles
========================================================

- Natural selection can generate clinal variation in allele frequency across geographic space.

- Selection can be detected by evaluating correlation between 
allele frequency and ecological gradients (used as proxies for selection pressures).

- Difficulty: Demography can also create similar variation, and correlation methods need to correct for demographic effects.




Model definition
========================================================

- Latent factor mixed models (LFMMs) are statistical regression models.

- LFMMs include unobserved variables, called **latent factors**, that correct the model for confounding effects.

- LFMMs belong to a broad class of GWAS statistical models.



Model Equation
========================================================

- LFMMs are defined by the following equation

$$
 Y = X B^T + U V^T + E
$$

- $Y$ is an $n \times p$ matrix of observations of $p$ variables (e.g., genotypes) on $n$ individuals

- $X$ is an $n \times d$ matrix of explanatory variables (e.g., phenotypes) measured for the $n$ individuals, 

- $B$ is a $p \times d$ matrix of effects for all explanatory variables, 

- $U$ is an $n \times K$ matrix of latent variables (confounders),

- $V$ is a $p \times d$ matrix of loadings for all latent variables.



Model Fit
========================================================

- Model fit can be performed by using several (at least 7) distinct methods.

- I'll present 3 algorithms

   1. least-squares estimation with **ridge** penalty (**lfmm::lfmm_ridge**)

   2. least-squares estimation with **lasso** penalty (**lfmm::lfmm_lasso**)
   
   3. Bayesian estimation with **sparse** priors (**LEA::lfmm**, slower)
   

- Other methods include **cate**, **sva** (2 methods), **famt**, etc.


Association testing
========================================================

- LFMMs perform statistical test of the null-hypothesis $B=0$ 

$$
 Y = X B^T + U V^T + E
$$


- where $B$ is the $p \times d$ matrix of effects for the explanatory variables,

- Null hypothesis testing: $B = 0$ (neutrality)



Loading the data 
========================================================

```{r}
dahu <- readRDS("sim1a.rds")
# extract scaled genotypes
scaled.genotype <- scale(as.matrix(t(dahu$G)))
# extract scaled phenotypes
x <- scale(as.matrix(dahu$phenotype1))
```




Determining the number of latent factors 
========================================================


Use principal component analysis of the genotype matrix to evaluate 'population structure' in the genotypic data. 

```{r}
pc <- prcomp(scaled.genotype)
plot(pc$sdev[1:20]^2, pch = 19)
points(5,pc$sdev[5]^2, type = "h", lwd = 3, col = "blue")
```




Model fit using ridge regression models 
========================================================

Model fit can be performed as follows


```{r}
lfmm.ridge <- lfmm::lfmm_ridge(Y = scaled.genotype, X = x, K = 5, lambda = 1e-5)
```

 - The **lfmm.ridge** object contains estimates for the 5 latent variables and for all effect sizes.
 
 - These estimates can used to determine the candidate loci (association testing).




Testing associations between genotypes (Y) and phenotypes (X)  
========================================================

We now apply the **lfmm_test** function


```{r}
lfmm.test <- lfmm::lfmm_test(Y = scaled.genotype, X = x, lfmm = lfmm.ridge, calibrate = "gif")

pv.ridge <- lfmm.test$calibrated.pvalue
```


```{r, echo = FALSE}
plot(-log10(pv.ridge), pch = 19, col = "blue")
```




Model fit using regression models with L1 penalty (lasso)
========================================================

Model fit can also be performed using a (sparse) penalty


```{r}
lfmm.lasso <- lfmm::lfmm_lasso(Y = scaled.genotype, X = x, K = 5, nozero.prop = 0.02)
```

 - The **lfmm.lasso** object contains new estimates for the 5 latent variables and for all effect sizes.
 
 - The **nozero.prop** parameter is a sparsity parameter indicating how many significant tests we should consider. 





Testing associations using the lasso estimates 
========================================================

We now apply the **lfmm_test** function to the **lfmm.lasso** object


```{r}
lfmm.test <- lfmm::lfmm_test(Y = scaled.genotype, X = x, lfmm = lfmm.lasso, calibrate = "gif")
pv.lasso <- lfmm.test$calibrated.pvalue
```


```{r, echo = FALSE}
plot(-log10(pv.lasso), pch = 19, col = "blue")
```


FDR control methods: qvalue
========================================================


```{r}
qv <- qvalue::qvalue(pv.ridge)
plot(qv)
```






Final step: extracting candidates
========================================================


```{r}
qv <- qvalue::qvalue(pv.ridge, fdr.level = 0.025)
candidates <- which(qv$significant)
```

```{r, echo = FALSE}
plot(-log10(pv.ridge), cex = .5, pch = 19, col = "grey")
points(candidates, -log10(pv.ridge[candidates]), pch = 19, col = "orange")
```




Additional comments:
========================================================

- **plink**-like preprocessing steps can improve signal detection: Filter out low frequency variants (MAF < 5-10%), use LD pruning when estimating latent factors

- Consider **LEA::lfmm** MCMC, slower but it could lead to more  results.

- See the markdown doc in the github repository


Questions?
========================================================

